{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36ca5ad4",
   "metadata": {},
   "source": [
    "## CA 4 - Part 2, LLMs Spring 2025\n",
    "\n",
    "- **Name:**\n",
    "- **Student ID:**\n",
    "\n",
    "---\n",
    "#### Your submission should be named using the following format: `CA4_LASTNAME_STUDENTID.ipynb`.\n",
    "\n",
    "---\n",
    "\n",
    "TA Email: miladmohammadi@ut.ac.ir\n",
    "\n",
    "##### *How to do this problem set:*\n",
    "\n",
    "- Some questions require writing Python code and computing results, and the rest of them have written answers. For coding problems, you will have to fill out all code blocks that say `YOUR CODE HERE`.\n",
    "\n",
    "- For text-based answers, you should replace the text that says ```Your Answer Here``` with your actual answer.\n",
    "\n",
    "- There is no penalty for using AI assistance on this homework as long as you fully disclose it in the final cell of this notebook (this includes storing any prompts that you feed to large language models). That said, anyone caught using AI assistance without proper disclosure will receive a zero on the assignment (we have several automatic tools to detect such cases). We're literally allowing you to use it with no limitations, so there is no reason to lie!\n",
    "\n",
    "---\n",
    "\n",
    "##### *Academic honesty*\n",
    "\n",
    "- We will audit the Colab notebooks from a set number of students, chosen at random. The audits will check that the code you wrote actually generates the answers in your notebook. If you turn in correct answers on your notebook without code that actually generates those answers, we will consider this a serious case of cheating.\n",
    "\n",
    "- We will also run automatic checks of Colab notebooks for plagiarism. Copying code from others is also considered a serious case of cheating.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86cccf5",
   "metadata": {},
   "source": [
    "## Text2SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c97a10",
   "metadata": {},
   "source": [
    "In this section, you will progressively build and evaluate multiple Text-to-SQL pipelines. You’ll start with a simple prompting-based baseline, then design a graph-based routing system using chain-of-thought and schema reasoning, and finally construct a ReAct agent that interacts with the schema via tools. Each stage demonstrates a different strategy for generating SQL from natural language using LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86892463",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e367a33b",
   "metadata": {},
   "source": [
    "This section prepares the environment and initializes the LLM model (Gemini) to be used in later parts of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d57ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f4a2c",
   "metadata": {},
   "source": [
    "#### Load API Key (2 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684e23a1",
   "metadata": {},
   "source": [
    "**Task:** Load the Gemini API key stored in the `.env` file and set it as an environment variable so it can be used to authenticate API requests later.\n",
    "\n",
    "* Use `dotenv` to load the file.\n",
    "* Extract the API key with `os.getenv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd477695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce1714",
   "metadata": {},
   "source": [
    "#### Create ChatModel (3 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b50a6f5",
   "metadata": {},
   "source": [
    "**Task:** Create an instance of the Gemini LLM using LangChain. You should configure the model with proper parameters for our task.\n",
    "\n",
    "Note: You may use any model that supports Structured Output and Tool Use. We recommend using gemini-2.5-flash-preview-05-20 from Google AI Studio, as it offers a generous free tier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c117040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8440112",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c1c0b",
   "metadata": {},
   "source": [
    "In this section, you'll build a simple baseline pipeline that directly converts a question and schema into a SQL query using a single prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abef3ecf",
   "metadata": {},
   "source": [
    "#### Baseline Function (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7452b396",
   "metadata": {},
   "source": [
    "**Task:** Implement a function that sends a system message defining the task, and a user message containing the input question and schema. The LLM should return the SQL query formatted as: \"```sql\\n[query]```\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd0eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baseline(question: str, schema: str):\n",
    "    #YOUR CODE HERE\n",
    "    return sql_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b335cbd8",
   "metadata": {},
   "source": [
    "#### Run and Evaluate (Estimated Run Time 5-10min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f328a0c2",
   "metadata": {},
   "source": [
    "Run your baseline function over the dataset provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538878ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from method_run import run_method\n",
    "import re\n",
    "\n",
    "def function_template(item):\n",
    "    result = run_baseline(item['question'], item['schema'])\n",
    "    # First try to extract query from markdown SQL block\n",
    "    match = re.search(r'```sql\\n(.*?)```', result, re.DOTALL)\n",
    "    if match:\n",
    "        query = match.group(1).strip()\n",
    "    else:\n",
    "        # If no markdown block found, try to extract just SQL query\n",
    "        query = result.strip()\n",
    "        # Remove any ```sql or ``` if present without proper formatting\n",
    "        query = re.sub(r'```sql|```', '', query).strip()\n",
    "    \n",
    "    print(f\"Question: {item['question']}\")\n",
    "    print(f\"Schema: {item['schema']}\")\n",
    "    print(f\"Generated SQL: {query}\\n\")\n",
    "    \n",
    "    return {**item, 'sql': query}\n",
    "\n",
    "run_method(function_template, SLEEP_TIME=10)\n",
    "\n",
    "#Run on mode=nano if you want to test it on a smaller dataset\n",
    "#run_method(function_template, SLEEP_TIME=10, mode=\"nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cd06f9",
   "metadata": {},
   "source": [
    "### Chain/Router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46affa4",
   "metadata": {},
   "source": [
    "Here, you will build a more advanced system that routes the query through different paths based on question difficulty. Easier questions go straight to query generation; harder ones go through schema path extraction first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa254aa",
   "metadata": {},
   "source": [
    "#### Define State (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7db5cc",
   "metadata": {},
   "source": [
    "**Task:** Define a `RouterGraphState` using `MessagesState` and `pydantic` that contains:\n",
    "* The input question and schema\n",
    "* The predicted difficulty level\n",
    "* The extracted schema path\n",
    "* The final query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from typing import Literal\n",
    "\n",
    "class RouterGraphState(MessagesState):\n",
    "    #YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696dc1c9",
   "metadata": {},
   "source": [
    "#### Node: Analyser (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ace53",
   "metadata": {},
   "source": [
    "**Task:** Build a node that:\n",
    "* Accepts a question and schema\n",
    "* Analyzes the difficulty (simple/moderate/challanging)\n",
    "* Uses the LLM’s structured output feature to return the difficulty\n",
    "\n",
    "**Steps**:\n",
    "\n",
    "1. Define a Pydantic class to hold the expected structured output.\n",
    "2. Use structure output mode of LLM to bind it to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1969dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class QuestionDifficaultyAnalysis(BaseModel):\n",
    "    #YOUR CODE HERE\n",
    "\n",
    "def analyser_node(state: RouterGraphState):\n",
    "    #YOUR CODE HERE\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f78d38c",
   "metadata": {},
   "source": [
    "#### Conditional Edge (2 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406d17e0",
   "metadata": {},
   "source": [
    "**Task:** Implement a branching function that decides whether to proceed to direct query generation or schema path extraction based on the difficulty label returned by the analyser.\n",
    "\n",
    "* If the difficulty is “easy”, go directly to query generation.\n",
    "* Otherwise, extract the schema path first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908afa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_schema_extraction_needed(state: RouterGraphState)->Literal[\"schema_path_extractor\", \"query_generator\"]:\n",
    "  #YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108c9d25",
   "metadata": {},
   "source": [
    "#### Node: Schema Extractor (3 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e159a0f9",
   "metadata": {},
   "source": [
    "**Task:** Implement a node that takes the question and schema and extracts a join path or sequence of relevant tables from the schema based on the question.\n",
    "\n",
    "* Use a simple prompt for this.\n",
    "* Store the result in the `schema_path` field of the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e82812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schema_path_extractor_node(state: RouterGraphState):\n",
    "    #YOUR CODE HERE\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091dc790",
   "metadata": {},
   "source": [
    "#### Node: Generator (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f374e09",
   "metadata": {},
   "source": [
    "**Task:** Generate the SQL query based on the question and schema.\n",
    "\n",
    "* If a schema path is available, include it in the prompt.\n",
    "* Save the output query in the `query` field of the state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a600328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_generator_node(state: RouterGraphState):\n",
    "    #YOUR CODE HERE\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b20d96c",
   "metadata": {},
   "source": [
    "#### Build Graph (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416b89b",
   "metadata": {},
   "source": [
    "**Task:** Assemble the full routing graph using the nodes and edges you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f58c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "router_graph_builder = StateGraph(RouterGraphState)\n",
    "\n",
    "#YOUR CODE HERE\n",
    "\n",
    "router_graph = router_graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204fab8e",
   "metadata": {},
   "source": [
    "#### Run and Evaluate (Estimated Run Time 10-15min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90f0bc7",
   "metadata": {},
   "source": [
    "**Task:** Run your compiled routing graph on a dataset. For each question:\n",
    "\n",
    "* Instantiate the `RouterGraphState` with the question and schema.\n",
    "* Run the graph to completion.\n",
    "* Extract and clean the query from the result.\n",
    "\n",
    "Use the `run_method` function to handle iteration and timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585c706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from method_run import run_method\n",
    "def run_router_graph(item):\n",
    "    response = router_graph.invoke(\n",
    "        RouterGraphState(\n",
    "            question=item['question'],\n",
    "            schema=item['schema'],\n",
    "            schema_path=None,\n",
    "            question_difficulty=None,\n",
    "            query=None\n",
    "        )\n",
    "    )\n",
    "    result = response[\"query\"]\n",
    "    # First try to extract query from markdown SQL block\n",
    "    match = re.search(r'```sql\\n(.*?)```', result, re.DOTALL)\n",
    "    if match:\n",
    "        query = match.group(1).strip()\n",
    "    else:\n",
    "        # If no markdown block found, try to extract just SQL query\n",
    "        query = result.strip()\n",
    "        # Remove any ```sql or ``` if present without proper formatting\n",
    "        query = re.sub(r'```sql|```', '', query).strip()\n",
    "    print(f\"Question: {item['question']}\")\n",
    "    print(f\"Schema: {item['schema']}\")\n",
    "    print(f\"Question Difficulty: {response['question_difficulty']}\")\n",
    "    if response[\"schema_path\"]:\n",
    "        print(f\"Schema Path: {response['schema_path']}\")\n",
    "    print(f\"Generated SQL: {query}\\n\")\n",
    "    return {**item, 'sql': query}\n",
    "\n",
    "\n",
    "run_method(run_router_graph, SLEEP_TIME=30)\n",
    "\n",
    "#Run on mode=nano if you want to test it on a smaller dataset\n",
    "#run_method(run_router_graph, SLEEP_TIME=10, mode=\"nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4666dff4",
   "metadata": {},
   "source": [
    "### Agent (ReAct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc99580",
   "metadata": {},
   "source": [
    "Now you will implement a full ReAct agent that incrementally solves the Text-to-SQL task using tools. The agent can explore tables and columns before finalizing the query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1df0a65",
   "metadata": {},
   "source": [
    "**You are not allowed to use 'Prebuilt Agent' of LangGraph. You have to build your own graph.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9505b9f8",
   "metadata": {},
   "source": [
    "#### Define Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b3582a",
   "metadata": {},
   "source": [
    "**Task:** Define three tools for the agent to interact with the schema:\n",
    "1. `get_samples_from_table`: Returns the first few rows of a table.\n",
    "2. `get_column_description`: Provides a human-readable description of a specific column.\n",
    "3. `execute`: Executes a SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab00e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from db_manager import DBManager\n",
    "db_manager = DBManager()\n",
    "\n",
    "@tool\n",
    "def get_samples_from_table(table_name: str, config: RunnableConfig):\n",
    "  \"\"\"Gets the first few rows (samples) from a specified table.\n",
    "\n",
    "  Args:\n",
    "    table_name: The name of the table from which to fetch samples.\n",
    "\n",
    "  Returns:\n",
    "    The first few rows from the specified table.\n",
    "  \"\"\"\n",
    "  db_name = config[\"configurable\"].get(\"database_name\")\n",
    "  result = db_manager.get_table_head(table_name, db_name=db_name)\n",
    "  return result\n",
    "\n",
    "@tool\n",
    "def get_column_description(table_name: str, column_name: str, config: RunnableConfig):\n",
    "  \"\"\"Provides a description for a specific column within a given table.\n",
    "\n",
    "  Args:\n",
    "    table_name: The name of the table containing the column.\n",
    "    column_name: The name of the column for which to get the description.\n",
    "\n",
    "  Returns:\n",
    "    A string containing the description of the specified column.\n",
    "  \"\"\"\n",
    "  db_name = config[\"configurable\"].get(\"database_name\")\n",
    "  result = db_manager.get_column_description(db_name, table_name, column_name)\n",
    "  return result\n",
    "\n",
    "@tool\n",
    "def execute(query: str, config: RunnableConfig):\n",
    "  \"\"\"Executes a given SQL query against the database.\n",
    "\n",
    "  Args:\n",
    "    query: The SQL query string to be executed.\n",
    "\n",
    "  Returns:\n",
    "    The result of the executed query. This could be a set of rows,\n",
    "    a confirmation message, or an error.\n",
    "  \"\"\"\n",
    "  db_name = config[\"configurable\"].get(\"database_name\")\n",
    "  result = db_manager.query(query, db_name)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66680244",
   "metadata": {},
   "source": [
    "#### Extra Tool (5+5 Bonus Points):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80baae9",
   "metadata": {},
   "source": [
    "**Task**: Create and integrate a new custom tool into the ReAct agent. To receive credit for this part, your tool must be meaningfully different from the existing three tools and provide practical value in helping the agent generate more accurate or efficient SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0308d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbe11d0",
   "metadata": {},
   "source": [
    "#### Create Tool Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_samples_from_table, get_column_description, execute]\n",
    "tools_node = ToolNode(tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8348623d",
   "metadata": {},
   "source": [
    "#### ReAct Agent Prompt (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d0f151",
   "metadata": {},
   "source": [
    "**Task:** Set up the agent node with planning, tool use, and final SQL generation prompts. For writing efficient prompt you can read this link.\n",
    "https://cookbook.openai.com/examples/gpt4-1_prompting_guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c8f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "REACT_SYS_PROMPT = \"\"\"\n",
    "#YOUR PROMPT HERE\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee385fd",
   "metadata": {},
   "source": [
    "#### Agent Node (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549f4b1",
   "metadata": {},
   "source": [
    "**Task:** Set up the agent node with models that have binded with tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4247575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def agent_node(state: MessagesState) -> MessagesState:\n",
    "    #For rate-limiting purposes, we will sleep for 10 seconds before invoking the LLM\n",
    "    time.sleep(10)\n",
    "    #YOUR CODE HERE\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe4d541",
   "metadata": {},
   "source": [
    "#### Build Graph (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bbf177",
   "metadata": {},
   "source": [
    "**Task:** Assemble the ReAct agent graph, connecting the agent node and tool node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d770ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import tools_condition\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class ConfigSchema(TypedDict):\n",
    "    database_name: str\n",
    "\n",
    "react_builder = StateGraph(MessagesState, config_schema=ConfigSchema)\n",
    "\n",
    "#YOUR CODE HERE\n",
    "\n",
    "react_graph = react_builder.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7aee0f",
   "metadata": {},
   "source": [
    "#### Run and Evaluate (Estimated Run Time 20min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4a2020",
   "metadata": {},
   "source": [
    "**Task:** Execute the ReAct agent pipeline on the dataset and collect SQL outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9184c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from method_run import run_method\n",
    "import re\n",
    "def run_react_agent_with_config(item):\n",
    "    question = item['question']\n",
    "    schema = item['schema']\n",
    "    user_prompt = f\"Question: {question}\\nSchema: {schema}\"\n",
    "    input_msg = HumanMessage(content=user_prompt)\n",
    "    input_config = {\"configurable\": {\"database_name\": item['db_id']}}\n",
    "    response = react_graph.invoke(MessagesState(messages=[input_msg]), config=input_config)\n",
    "\n",
    "    for msg in response[\"messages\"]:\n",
    "        msg.pretty_print()\n",
    "        \n",
    "    # If last AI Message is a list of messages, we need to extract the last one\n",
    "    last_msg = response[\"messages\"][-1].content\n",
    "    if isinstance(last_msg, list):\n",
    "        last_msg = last_msg[-1]\n",
    "\n",
    "    # First try to extract query from markdown SQL block\n",
    "    match = re.search(r'```sql\\n(.*?)```', last_msg, re.DOTALL)\n",
    "    if match:\n",
    "        query = match.group(1).strip()\n",
    "    else:\n",
    "        # If no markdown block found, try to extract just SQL query\n",
    "        query = last_msg.strip()\n",
    "        # Remove any ```sql or ``` if present without proper formatting\n",
    "        query = re.sub(r'```sql|```', '', query).strip()\n",
    "\n",
    "    return {**item, 'sql': query}\n",
    "\n",
    "#Run agent on mode=nano, it's not needed to run on full dataset\n",
    "run_method(run_react_agent_with_config, SLEEP_TIME=20, mode=\"nano\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
